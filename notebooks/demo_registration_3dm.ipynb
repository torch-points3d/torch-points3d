{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from plyfile import PlyData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"40%\" src=\"https://raw.githubusercontent.com/nicolas-chaulet/torch-points3d/master/docs/logo.png\" />\n",
    "</p>\n",
    "\n",
    "# Registration Demo on 3DMatch\n",
    "\n",
    "In this task, we will show a demonstration of registration on 3DMatch using a pretrained network from scratch.\n",
    "\n",
    "First let's load some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the data\n",
    "\n",
    "def read_ply(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        plydata = PlyData.read(f)\n",
    "    vertex = plydata['vertex']\n",
    "    return np.vstack((vertex['x'], vertex['y'], vertex['z'])).T\n",
    "path_s = \"data/3DMatch/redkitchen_000.ply\"\n",
    "path_t = \"data/3DMatch/redkitchen_010.ply\"\n",
    "\n",
    "pcd_s = read_ply(path_s)\n",
    "pcd_t = read_ply(path_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put the point cloud in the class Batch, apply some transformation (transform data into sparse voxels, add ones). We can load the model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing import\n",
    "from torch_points3d.core.data_transform import GridSampling3D, AddOnes, AddFeatByKey\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# Model\n",
    "from torch_points3d.applications.pretrained_api import PretainedRegistry\n",
    "\n",
    "# post processing\n",
    "from torch_points3d.metrics.registration_metrics import get_matches, fast_global_registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([GridSampling3D(mode='last', size=0.02, quantize_coords=True), AddOnes(), AddFeatByKey(add_to_x=True, feat_name=\"ones\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = transform(Batch(pos=torch.from_numpy(pcd_s).float(), batch=torch.zeros(pcd_s.shape[0]).long()))\n",
    "data_t = transform(Batch(pos=torch.from_numpy(pcd_t).float(), batch=torch.zeros(pcd_t.shape[0]).long()))\n",
    "\n",
    "\n",
    "\n",
    "model = PretainedRegistry.from_pretrained(\"minkowski-registration-3dmatch\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_pcd_s = o3d.geometry.PointCloud()\n",
    "o3d_pcd_s.points = o3d.utility.Vector3dVector(data_s.pos.cpu().numpy())\n",
    "o3d_pcd_s.paint_uniform_color([0.9, 0.7, 0.1])\n",
    "\n",
    "o3d_pcd_t = o3d.geometry.PointCloud()\n",
    "o3d_pcd_t.points = o3d.utility.Vector3dVector(data_t.pos.cpu().numpy())\n",
    "o3d_pcd_t.paint_uniform_color([0.1, 0.7, 0.9])\n",
    "# visualizer = o3d.JVisualizer()\n",
    "# visualizer.add_geometry(o3d_pcd_s)\n",
    "# visualizer.add_geometry(o3d_pcd_t)\n",
    "# visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.set_input(data_s, \"cuda\")\n",
    "    output_s = model.forward()\n",
    "    model.set_input(data_t, \"cuda\")\n",
    "    output_t = model.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we have our feature let's match our features. We will select 5000 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_s = torch.randint(0, len(output_s), (5000, ))\n",
    "rand_t = torch.randint(0, len(output_t), (5000, ))\n",
    "\n",
    "matches = get_matches(output_s[rand_s], output_t[rand_t])\n",
    "\n",
    "T_est = fast_global_registration(data_s.pos[rand_s][matches[:, 0]], data_t.pos[rand_t][matches[:, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = o3d.JVisualizer()\n",
    "visualizer.add_geometry(o3d_pcd_s)\n",
    "visualizer.add_geometry(o3d_pcd_t)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = o3d.JVisualizer()\n",
    "visualizer.add_geometry(o3d_pcd_s.transform(T_est.cpu().numpy()))\n",
    "visualizer.add_geometry(o3d_pcd_t)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Let's try to visualize features to see what the network have learnt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_color_from_features(list_feat):\n",
    "    feats = np.vstack(list_feat)\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(feats)\n",
    "    min_col = pca.transform(feats).min(axis=0)\n",
    "    max_col = pca.transform(feats).max(axis=0)\n",
    "    list_color = []\n",
    "    for feat in list_feat:\n",
    "        color = pca.transform(feat)\n",
    "        color = (color - min_col) / (max_col - min_col)\n",
    "        list_color.append(color)\n",
    "    return list_color\n",
    "list_color = compute_color_from_features([output_s.detach().cpu().numpy(), output_t.detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_pcd_s.colors = o3d.utility.Vector3dVector(list_color[0])\n",
    "visualizer = o3d.JVisualizer()\n",
    "visualizer.add_geometry(o3d_pcd_s)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d_pcd_t.colors = o3d.utility.Vector3dVector(list_color[1])\n",
    "visualizer = o3d.JVisualizer()\n",
    "visualizer.add_geometry(o3d_pcd_t)\n",
    "visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
