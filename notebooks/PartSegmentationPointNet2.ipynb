{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PartSegmentationPointNet2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolas-chaulet/torch-points3d/blob/new_notebook/notebooks/PartSegmentationPointNet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMPGNDv1vDn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup packages\n",
        "!pip install torch==1.3.1 pyvista torchvision==0.4.2 pytorch-lightning\n",
        "!pip install --upgrade jsonschema\n",
        "!pip install torch-points3d\n",
        "!apt-get install -qq xvfb libgl1-mesa-glx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGza3XTYvQNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from omegaconf import OmegaConf\n",
        "import pyvista as pv\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from omegaconf import OmegaConf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q44YjGjrvg2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIR = \"\" # Replace with your root directory, the data will go in DIR/data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izN8KU_tv5JR",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img width=\"40%\" src=\"https://raw.githubusercontent.com/nicolas-chaulet/torch-points3d/master/docs/logo.png\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgox3ksbv-s1",
        "colab_type": "text"
      },
      "source": [
        "# Segmenting objects in part with PointNet2\n",
        "In this notebook we will solve the task of segmenting an object into its sub parts by using a [Pointnet2](https://arxiv.org/abs/1706.02413) deep neural network.\n",
        "We will work on [ShapeNet](https://www.shapenet.org/) dataset which contains 48,600 3D models over 55 common categories with part annotations. We will show you how you can use Torch Points3D to setup a Pointnet2 backbone with a multi head classifier and train it on ShapeNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyFtUQhGybFc",
        "colab_type": "text"
      },
      "source": [
        "## The dataset\n",
        "We use Torch Points3D version of ShapeNet that provides automatic download (be patient, it takes some time...) of the data, a tested metric tracker as well as methods for pre computing the spatial operations such as neighbour search and grid sampling on CPU.\n",
        "\n",
        "Let's start with the data config (if you want more details about that part of Torch Points3D please refer to this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRS6vxSvjRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shapenet_yaml = \"\"\"\n",
        "class: shapenet.ShapeNetDataset\n",
        "task: segmentation\n",
        "dataroot: %s\n",
        "normal: True                                    # Use normal vectors as features\n",
        "first_subsampling: 0.02                       # Grid size of the input data\n",
        "category: \"Airplane\"\n",
        "pre_transforms:                               # Offline transforms, done only once\n",
        "    - transform: NormalizeScale           \n",
        "    - transform: GridSampling\n",
        "      params:\n",
        "        size: ${first_subsampling}\n",
        "train_transforms:                             # Data augmentation pipeline\n",
        "    - transform: RandomNoise\n",
        "      params:\n",
        "        sigma: 0.01\n",
        "        clip: 0.05\n",
        "    - transform: RandomScaleAnisotropic\n",
        "      params:\n",
        "        scales: [0.9,1.1]\n",
        "    - transform: FixedPoints\n",
        "      lparams: [2048]\n",
        "test_transforms:\n",
        "    - transform: FixedPoints\n",
        "      lparams: [2048]\n",
        "\"\"\" % (os.path.join(DIR,\"data\")) \n",
        "\n",
        "params = OmegaConf.create(shapenet_yaml)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQFRmfUYzXX1",
        "colab_type": "code",
        "outputId": "1c40cd62-8d92-4f26-f251-a2f775be8c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from torch_points3d.datasets.segmentation import ShapeNetDataset\n",
        "dataset = ShapeNetDataset(params)\n",
        "dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset: ShapeNetDataset \n",
              "\u001b[0;95mpre_transform \u001b[0m= Compose([\n",
              "    NormalizeScale(),\n",
              "    GridSampling(grid_size=0.02, quantize_coords=False, mode=mean),\n",
              "])\n",
              "\u001b[0;95mtest_transform \u001b[0m= Compose([\n",
              "    FixedPoints(2048, replace=True),\n",
              "])\n",
              "\u001b[0;95mtrain_transform \u001b[0m= Compose([\n",
              "    RandomNoise(sigma=0.01, clip=0.05),\n",
              "    RandomScaleAnisotropic([0.9, 1.1]),\n",
              "    FixedPoints(2048, replace=True),\n",
              "])\n",
              "\u001b[0;95mval_transform \u001b[0m= None\n",
              "\u001b[0;95minference_transform \u001b[0m= Compose([\n",
              "    NormalizeScale(),\n",
              "    GridSampling(grid_size=0.02, quantize_coords=False, mode=mean),\n",
              "    FixedPoints(2048, replace=True),\n",
              "])\n",
              "Size of \u001b[0;95mtrain_dataset \u001b[0m= 2349\n",
              "Size of \u001b[0;95mtest_dataset \u001b[0m= 341\n",
              "Size of \u001b[0;95mval_dataset \u001b[0m= 0\n",
              "\u001b[0;95mBatch size =\u001b[0m None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuaWoTCDRDlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e1a89b3-8dd6-463b-d05e-c373e787c89c"
      },
      "source": [
        "dataset.class_to_segments"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Airplane': [0, 1, 2, 3]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxKveewnIkSe",
        "colab_type": "text"
      },
      "source": [
        "Get the tracker which has already built-in metric for this **dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5zmAsXiIU36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracker = dataset.get_tracker(False, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLSGJVf30G1C",
        "colab_type": "text"
      },
      "source": [
        "## Model for part segmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk2LyH-IT2KG",
        "colab_type": "text"
      },
      "source": [
        "**The** model we implement here follows the main architecture proposed in the [original repo](https://github.com/charlesq34/pointnet2):\n",
        "\n",
        "It is built using the U-Net architecture with an encoder and decoder.\n",
        "\n",
        "The encoder is a succession of 2 steps\n",
        "\n",
        "### The encoder\n",
        "\n",
        "* sampling and grouping: First, it downsamples the pointcloud using [Farthest Point Sampling method](https://en.wikipedia.org/wiki/Farthest-first_traversal) and secondly, finds local neighbours using radius search (could be knn, random or anything else)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=\"70%\" src=\"http://www.open3d.org/docs/release/_images/kdtree.png\">\n",
        "</p>\n",
        "\n",
        "* pointnet: It is a shared MLP applied on all the local neighborhood independently generating the features for the next layer\n",
        "\n",
        "### The decoder\n",
        "\n",
        "For each point coming from the skip link concatenation, we find the k closest in the previously downsampled point cloud.\n",
        "\n",
        "The features are then interpolated using the distance squared as follow:\n",
        "\n",
        "$\\mathbf{f}(y) = \\frac{\\sum_{i=1}^k w(x_i) \\mathbf{f}(x_i)}{\\sum_{i=1}^k\n",
        "        w(x_i)} \\textrm{, where } w(x_i) = \\frac{1}{d(\\mathbf{p}(y),\n",
        "        \\mathbf{p}(x_i))^2}$\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=\"70%\" src=\"https://raw.githubusercontent.com/charlesq34/pointnet2/master/doc/teaser.jpg\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5pl2g9ap1Fq",
        "colab_type": "text"
      },
      "source": [
        "Our `sample` contains as expected a batch of 16 samples with 2048 3d points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsOeG_VXW5lC",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-o57u-VJ-qe",
        "colab_type": "text"
      },
      "source": [
        "# Using the BaseModel\n",
        "\n",
        "The BaseModel is inspired from the excellent [junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/base_model.py) project on github.\n",
        "\n",
        "We extended its core functionality to be adapted to pointcloud.\n",
        "\n",
        "The user will have to implement only \n",
        "\n",
        "* ```set_input(self, data, device)```: This function will receive an object data from the dataloader with Pytorch Tensors as attributes as well as the current devide to be used. The user will have to implement its own logic to handle the sample data brought to its model.\n",
        "\n",
        "* ```forward(self, *args, **kwargs)```: Forward data through the model and compute loss\n",
        "\n",
        "* ```backward(self)```: Backward loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg3O2swzW7if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_points3d.models.base_model import BaseModel\n",
        "from torch_points3d.applications.pointnet2 import PointNet2\n",
        "\n",
        "class Model(BaseModel):\n",
        "    def __init__(self, params):\n",
        "        super(Model, self).__init__(params)\n",
        "\n",
        "        self.unet = PointNet2(\n",
        "            architecture=\"unet\", \n",
        "            input_nc=3, \n",
        "            num_layers=3, \n",
        "            multiscale=True,\n",
        "            output_nc = int(params.num_classes)\n",
        "            )\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "        self.loss_names = [\"loss_seg\"]\n",
        "\n",
        "    def set_input(self, data, device):\n",
        "        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n",
        "        Parameters:\n",
        "            input: a dictionary that contains the data itself and its metadata information.\n",
        "        \"\"\"\n",
        "        data = data.to(device)\n",
        "        self.data = data\n",
        "        self.batch_size = data.pos.shape[0]\n",
        "        self.labels = data.y\n",
        "        self.batch_idx = data.batch\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        \"\"\"Run forward pass. This will be called by both functions <optimize_parameters> and <test>.\"\"\"\n",
        "\n",
        "        # Forward through unet and classifier\n",
        "        data_out = self.unet(self.data)\n",
        "        self.output = self.log_softmax(data_out.x.squeeze()).permute((0, 2, 1))\n",
        "\n",
        "        # Set loss for the backward pass\n",
        "        self.loss_seg = F.nll_loss(self.output.contiguous().view((-1, 4)), self.labels.flatten())\n",
        "        return self.output\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n",
        "        # caculate the intermediate results if necessary; here self.output has been computed during function <forward>\n",
        "        # calculate loss given the input and intermediate results\n",
        "        self.loss_seg.backward()  # calculate gradients of network G w.r.t. loss_G\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFaIG1SBchHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = \"\"\"conv_type: \"dense\"\n",
        "\"\"\"\n",
        "params = OmegaConf.create(opt)\n",
        "params.cat_to_seg = dataset.class_to_segments\n",
        "params.num_classes = dataset.num_classes\n",
        "model = Model(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUBiv8FDUMS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "730c359f-f20c-4aa6-dcf7-584cdfb14574"
      },
      "source": [
        "model.unet"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PointNet2Unet(\n",
              "  (down_modules): ModuleList(\n",
              "    (0): PointNetMSGDown(\n",
              "      (mlps): ModuleList(\n",
              "        (0): MLP2D(\n",
              "          (0): Conv2D(\n",
              "            (0): Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (1): Conv2D(\n",
              "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (2): Conv2D(\n",
              "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "        )\n",
              "        (1): MLP2D(\n",
              "          (0): Conv2D(\n",
              "            (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (1): Conv2D(\n",
              "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (2): Conv2D(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "        )\n",
              "        (2): MLP2D(\n",
              "          (0): Conv2D(\n",
              "            (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (1): Conv2D(\n",
              "            (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (2): Conv2D(\n",
              "            (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): PointNetMSGDown(\n",
              "      (mlps): ModuleList(\n",
              "        (0): MLP2D(\n",
              "          (0): Conv2D(\n",
              "            (0): Conv2d(323, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (1): Conv2D(\n",
              "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (2): Conv2D(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "        )\n",
              "        (1): MLP2D(\n",
              "          (0): Conv2D(\n",
              "            (0): Conv2d(323, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (1): Conv2D(\n",
              "            (0): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "          (2): Conv2D(\n",
              "            (0): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): LeakyReLU(negative_slope=0.01)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inner_modules): ModuleList(\n",
              "    (0): GlobalDenseBaseModule: 790784 (aggr=max, MLP2D(\n",
              "      (0): Conv2D(\n",
              "        (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (1): Conv2D(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (2): Conv2D(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "    ))\n",
              "  )\n",
              "  (up_modules): ModuleList(\n",
              "    (0): DenseFPModule: 459776 (MLP2D(\n",
              "      (0): Conv2D(\n",
              "        (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (1): Conv2D(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "    ))\n",
              "    (1): DenseFPModule: 180992 (MLP2D(\n",
              "      (0): Conv2D(\n",
              "        (0): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (1): Conv2D(\n",
              "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "    ))\n",
              "    (2): DenseFPModule: 33664 (MLP2D(\n",
              "      (0): Conv2D(\n",
              "        (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (1): Conv2D(\n",
              "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "    ))\n",
              "  )\n",
              "  (mlp): Seq(\n",
              "    (0): Conv1D(\n",
              "      (0): Conv1d(128, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
              "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Bx8GjE3Kt7",
        "colab_type": "text"
      },
      "source": [
        "## The data loaders\n",
        "Pointnet2 has been implemented using the \"dense\" data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1k4CNG12RXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORKERS = 4\n",
        "BATCH_SIZE = 4\n",
        "dataset.create_dataloaders(\n",
        "    model,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    num_workers=NUM_WORKERS, \n",
        "    shuffle=True, \n",
        "    precompute_multi_scale=False \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wdS3y_aVIbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e11197e9-a4fb-4237-8dd0-7660f9c1fa29"
      },
      "source": [
        "sample = next(iter(dataset.train_dataloader))\n",
        "sample.keys"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x', 'y', 'pos', 'category']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7_TS_BKIwMU",
        "colab_type": "text"
      },
      "source": [
        "Let's create an Adam optimizer for training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_kiVmC4I3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model._optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3flL0OH1F757",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
        "from torch_points3d.utils.colors import COLORS\n",
        "\n",
        "def train_epoch(epoch, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    tracker.reset(\"train\")\n",
        "    train_loader = dataset.train_dataloader\n",
        "    iter_data_time = time.time()\n",
        "    with Ctq(train_loader) as tq_train_loader:\n",
        "        for i, data in enumerate(tq_train_loader):\n",
        "            t_data = time.time() - iter_data_time\n",
        "            iter_start_time = time.time()\n",
        "            model.set_input(data, device)\n",
        "            model.optimize_parameters(epoch, dataset.batch_size)\n",
        "\n",
        "            tq_train_loader.set_postfix(\n",
        "                **tracker.get_metrics(),\n",
        "                data_loading=float(t_data),\n",
        "                iteration=float(time.time() - iter_start_time),\n",
        "                color=COLORS.TRAIN_COLOR\n",
        "            )\n",
        "\n",
        "            iter_data_time = time.time()\n",
        "\n",
        "def test_epoch(epoch, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    tracker.reset(\"test\")\n",
        "    test_loader = dataset.test_dataloaders[0]\n",
        "    iter_data_time = time.time()\n",
        "    with Ctq(test_loader) as tq_test_loader:\n",
        "        for i, data in enumerate(tq_test_loader):\n",
        "            t_data = time.time() - iter_data_time\n",
        "            iter_start_time = time.time()\n",
        "            model.set_input(data, device)\n",
        "            model.optimize_parameters(epoch, dataset.batch_size)\n",
        "\n",
        "            tq_test_loader.set_postfix(\n",
        "                **tracker.get_metrics(),\n",
        "                data_loading=float(t_data),\n",
        "                iteration=float(time.time() - iter_start_time),\n",
        "                color=COLORS.TRAIN_COLOR\n",
        "            )\n",
        "\n",
        "            iter_data_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpp6gZFcF8_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "a7668b21-9d5a-431d-92ef-ad65ba6480d9"
      },
      "source": [
        "import time\n",
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "  print(\"=========== EPOCH %i ===========\" % epoch)\n",
        "  time.sleep(0.5)\n",
        "  train_epoch(epoch, 'cuda')\n",
        "  tracker.publish(epoch)\n",
        "  test_epoch(epoch, 'cuda')\n",
        "  tracker.publish(epoch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== EPOCH 0 ===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|â–Ž         | 19/588 [00:02<01:00,  9.37it/s, \u001b[0;92mdata_loading=0.003, iteration=0.083, train_Cmiou=0    , train_Imiou=0    \u001b[0m)]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0a2dc3033d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=========== EPOCH %i ===========\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-642954f11684>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0miter_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             tq_train_loader.set_postfix(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_points3d/models/base_model.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self, epoch, batch_size)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lr_scheduler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y69S3OsL2UKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/version_4/ # Change for your log location"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeHV07s0L_Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}