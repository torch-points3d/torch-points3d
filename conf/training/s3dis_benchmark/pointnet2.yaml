# @package training
# Those arguments defines the training hyper-parameters
epochs: 300
num_workers: 2
batch_size: 8
cuda: 0
precompute_multi_scale: False # Compute multiscate features on cpu for faster training / inference
optim:
  base_lr: 0.01
  grad_clip: 100
  optimizer:
    class: SGD
    params:
      momentum: 0.98
      lr: ${training.optim.base_lr} # The path is cut from training
      weight_decay: 1e-3
  lr_scheduler: ${lr_scheduler}
  bn_scheduler:
    bn_policy: "step_decay"
    params:
      bn_momentum: 0.02
      bn_decay: 0.9
      decay_step: 1000
      bn_clip: 1e-2
weight_name: "latest" # Used during resume, select with model to load from [miou, macc, acc..., latest]
enable_cudnn: True
checkpoint_dir: ""

# Those arguments within experiment defines which model, dataset and task to be created for benchmarking
# parameters for Weights and Biases
wandb:
  entity: nicolas
  project: s3dis-benchmark
  log: True
  notes: "Pointnet++ baseline"
  name: "pointnet2"
  public: True # It will be display the model within wandb log, else not.


# parameters for TensorBoard Visualization
tensorboard:
  log: False
